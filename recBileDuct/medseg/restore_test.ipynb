{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from os.path import join\n",
    "from skimage import morphology\n",
    "from scipy.ndimage import zoom\n",
    "import medpy.metric.binary as metric\n",
    "\n",
    "def load_json(file: str):\n",
    "    with open(file, 'r') as f:\n",
    "        a = json.load(f)\n",
    "    return a\n",
    "\n",
    "def load_pickle(file: str, mode: str = 'rb'):\n",
    "    with open(file, mode) as f:\n",
    "        a = pickle.load(f)\n",
    "    return a\n",
    "\n",
    "def get_attribute(case_dic):\n",
    "    sample_slices = 3\n",
    "    name = case_dic['name']\n",
    "    data = np.load(case_dic['preprocess_npy']) # shape: (3, all_slices, consecutive slices, h, w)\n",
    "    properties = load_pickle(case_dic['preprocess_pkl'])\n",
    "    GT = sitk.GetArrayFromImage(sitk.ReadImage(case_dic['label']))\n",
    "    # 计算取样的个数: 3/5/7\n",
    "    consecutive_slices = data.shape[2]\n",
    "    mid_slice = consecutive_slices // 2\n",
    "    image = data[0][:, mid_slice-sample_slices//2:mid_slice+sample_slices//2+1,...].copy()\n",
    "    return name, image, GT, properties\n",
    "\n",
    "def pad2origin(arr, box, origin_shape, extend_slices=0):\n",
    "\n",
    "    pad_arr = np.pad(arr, ((box[0][0]+extend_slices, origin_shape[0]-box[0][1]+extend_slices), \n",
    "                            (box[1][0], origin_shape[1]-box[1][1]), \n",
    "                            (box[2][0], origin_shape[2]-box[2][1])), 'constant', constant_values=(0, 0))\n",
    "    assert pad_arr.shape[0] == origin_shape[0] and pad_arr.shape[1] == origin_shape[1] and pad_arr.shape[2] == origin_shape[2]\n",
    "    return pad_arr\n",
    "def reduction_for2D(predict, properties):\n",
    "    \n",
    "    restore_label = lambda label, x, y: zoom(label, (1.0, x / 256, y / 256), order=0)\n",
    "    predict = restore_label(predict, properties['crop_shape'][1], properties['crop_shape'][2])\n",
    "    predict = pad2origin(predict, properties['liver_box'], properties['origin_shape'], 0)\n",
    "\n",
    "    return predict\n",
    "\n",
    "def cal_metric(PR, GT):\n",
    "    assert len(PR.shape) == 3 and len(PR.shape) == len(GT.shape)\n",
    "    res = {}\n",
    "    res['dice'] = metric.dc(PR, GT)\n",
    "    res['jc'] = metric.jc(PR, GT)\n",
    "    res['precition'] = metric.precision(PR, GT)\n",
    "    res['recall'] = metric.recall(PR, GT)\n",
    "    res['specificity'] = metric.specificity(PR, GT)\n",
    "    return res\n",
    "\n",
    "def print_metrics(metric_res):\n",
    "    avg = {}        \n",
    "    for name, case_metric in metric_res.items():\n",
    "        print('Case-name: ', name)\n",
    "        for key, value in case_metric.items():\n",
    "            print('{}: {}'.format(key, value))\n",
    "            if key not in avg.keys():\n",
    "                avg[key] = value\n",
    "            else:\n",
    "                avg[key] += value\n",
    "        print('\\n')\n",
    "    print('AVG:')\n",
    "    for key, value in avg.items():\n",
    "        print('{}: {}'.format(key, value / len(metric_res.keys())))\n",
    "    print('\\n')\n",
    "\n",
    "def postprocess(pre, threshhold=200):\n",
    "    post_arr = morphology.remove_small_objects(pre.astype(np.bool8), threshhold, connectivity=3)\n",
    "    return post_arr.astype(np.float32)\n",
    "\n",
    "def get_image_from_array(arr, properties):\n",
    "        \n",
    "    image = sitk.GetImageFromArray(arr)\n",
    "    image.SetOrigin(properties['itk_origin'])\n",
    "    image.SetDirection(properties['itk_direction'])\n",
    "    image.SetSpacing(properties['itk_spacing'])\n",
    "\n",
    "    return image\n",
    "\n",
    "def save_predict(arr, case_name, properties, save_dir='/data1/zfx/code/latentAugmentation/predict'):\n",
    "\n",
    "    label = get_image_from_array(arr, properties)\n",
    "    sitk.WriteImage(label, join(save_dir, case_name+'.nii.gz'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = '/data1/zfx/code/latentAugmentation/medseg/saved/train_BileDuct_keep-origin-false_n_cls_2/BileDuct/cooperative_training/6/model/best/checkpoints/report/pred_npy'\n",
    "test_json = load_json('/data1/zfx/data/BileDuct/preprocessed_data/preprocess_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save case:  BileDuct_002  done...\n",
      "save case:  BileDuct_010  done...\n",
      "save case:  BileDuct_012  done...\n",
      "Case-name:  BileDuct_002\n",
      "dice: 0.8088799627012875\n",
      "jc: 0.6790918944959653\n",
      "precition: 0.8228143651407475\n",
      "recall: 0.7954096603092202\n",
      "specificity: 0.9998067904116106\n",
      "\n",
      "\n",
      "Case-name:  BileDuct_010\n",
      "dice: 0.7453131427899778\n",
      "jc: 0.5940232325755683\n",
      "precition: 0.8054108980058428\n",
      "recall: 0.6935613241942541\n",
      "specificity: 0.9999609433516458\n",
      "\n",
      "\n",
      "Case-name:  BileDuct_012\n",
      "dice: 0.7960017145714762\n",
      "jc: 0.6611319336623187\n",
      "precition: 0.9175542135602526\n",
      "recall: 0.7028871225502565\n",
      "specificity: 0.9999376698333615\n",
      "\n",
      "\n",
      "AVG:\n",
      "dice: 0.7833982733542472\n",
      "jc: 0.6447490202446174\n",
      "precition: 0.8485931589022809\n",
      "recall: 0.7306193690179104\n",
      "specificity: 0.9999018011988726\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_res = {}\n",
    "for case_dic in test_json['test']:\n",
    "    case_name, image, GT, properties = get_attribute(case_dic)\n",
    "    case_id = case_name.split('_')[-1]\n",
    "    soft_pred = np.load(join(pred_path, case_id + \"_soft_pred.npy\"))\n",
    "    PR = torch.from_numpy(soft_pred).max(1)[1].numpy()\n",
    "    restore_PR = reduction_for2D(PR, properties)\n",
    "    postprocess_PR = postprocess(pre=restore_PR)\n",
    "    metric_res[case_name] = cal_metric(postprocess_PR, GT)\n",
    "    save_predict(postprocess_PR, case_name, properties, save_dir='/data1/zfx/code/latentAugmentation/predict/cop-6/')\n",
    "    print('save case: ', case_name, ' done...')\n",
    "\n",
    "print_metrics(metric_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = '/data1/zfx/code/latentAugmentation/medseg/saved/train_BileDuct_keep-origin-false_n_cls_2/BileDuct/cooperative_training/5/model/best/checkpoints/report/pred_npy'\n",
    "test_json = load_json('/data1/zfx/data/BileDuct/preprocessed_data/preprocess_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002\n",
      "010\n",
      "odict_keys(['liver_box', 'size', 'itk_origin', 'itk_spacing', 'itk_direction', 'origin_shape', 'crop_shape'])\n",
      "[449 512 512]\n",
      "[[291, 425], [120, 359], [68, 353]]\n",
      "(449, 512, 512)\n",
      "(134, 239, 285)\n",
      "odict_keys(['liver_box', 'size', 'itk_origin', 'itk_spacing', 'itk_direction', 'origin_shape', 'crop_shape'])\n",
      "[449 512 512]\n",
      "[[291, 425], [120, 359], [68, 353]]\n",
      "(449, 512, 512)\n",
      "(134, 239, 285)\n"
     ]
    }
   ],
   "source": [
    "for case_dic in test_json['test']:\n",
    "    case_name, image, GT, properties = get_attribute(case_dic)\n",
    "    case_id = case_name.split('_')[-1]\n",
    "    print(case_id)\n",
    "    if case_id == '010':\n",
    "        print(properties.keys())\n",
    "        print(properties['size'])\n",
    "        print(properties['liver_box'])\n",
    "        print(properties['origin_shape'])\n",
    "        print(properties['crop_shape'])\n",
    "\n",
    "        crop_properties = load_pickle(case_dic['crop_pkl'])\n",
    "        print(crop_properties.keys())\n",
    "        print(crop_properties['size'])\n",
    "        print(crop_properties['liver_box'])\n",
    "        print(crop_properties['origin_shape'])\n",
    "        print(crop_properties['crop_shape'])\n",
    "\n",
    "\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zfx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
